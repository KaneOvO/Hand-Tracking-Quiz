# Hand-Tracking-Quiz



Deployment Page:  https://kaneovo.github.io/Hand-Tracking-Quiz/



Project Overview: This project is a hand tracking quiz. When used, the program will ask questions to the user in order from a pre-designed question bank, and track the user's hand position in real time through the camera to detect the user's answer. Then give corresponding feedback based on the user's answer.


User Manual: To use this program, you first need to agree to the camera permission. Then the software will ask you questions and display four answer boxes. You need to move your right hand and place it in the answer box you want to choose. When your hand moves to the answer box, the answer box will turn into a red frame. If you want to confirm the choice, you need to keep your hand on the answer box you want to choose for three seconds. After three seconds, the answer box will turn gold to indicate that you have confirmed the answer. The system will then give feedback based on your answer, and if the answer is correct, it will move on to the next question.



Ideal environment: I believe that my project could be used in interactive activities such as quiz events held during the opening of large shopping malls, or in preschool classrooms for children. The ideal installation environment should be spacious and well-lit indoor spaces, allowing participants to move freely while ensuring that the audience can safely watch the demonstration. 



Hardware List: This project primarily relies on three pieces of hardware: a camera, a display screen, and a computer. The specific costs can vary depending on the usage environment. For events in large shopping malls, high-precision cameras and large screens or a combination of giant curtains and projectors might be necessary. These costs could reach tens of thousands of dollars. However, for interactive classrooms, a laptop computer may suffice, reducing the cost to just a few hundred dollars.



Immersive experience design: To enhance the immersive experience of the project, my plan focuses on two aspects. Firstly, in terms of visuals, I plan to incorporate dynamic LED lighting. The LED lights will change in real-time according to different questions, such as switching to warm colors for questions about deserts and cool colors for questions about the starry sky. On the auditory side, I will design specific sound effects for different questions and play them during the corresponding questions. For example, the sound of water will be played for questions related to the ocean, and animal calls will be played for questions related to animals. By adding these features, the immersive experience for participants can be significantly improved, providing them with a better experience.



When making this project, Asked chatgpt about JavaScript hand tracking and learned how to use the TensorFlow library and the Handpose model.
